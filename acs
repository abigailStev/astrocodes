#!/usr/bin/env python

import os
from urllib.request import urlopen
import json
import sys
import argparse
from collections import OrderedDict
from pprint import pprint

import requests
from bs4 import BeautifulSoup


DATA_DIR = "data"

# PYPI_CLASSIFIER_URL: To get the URL for a given classifier, go to
# PyPI's "browse" page (https://pypi.python.org/pypi?%3Aaction=browse),
# browse to the classifier you want, and copy the URL.
PYPI_MAIN_URL = "https://pypi.python.org/pypi?%3Aaction=index"
PYPI_CLASSIFIER_URL = ("https://pypi.python.org/pypi"
                       "?:action=browse&show=all&c=387")
PYPI_PACKAGE_URL = "https://pypi.python.org/pypi/{0}/json"
PYPI_DATA_DIR = os.path.join(DATA_DIR, "pypi")

ASCL_URL = "http://ascl.net/code/json"
ASCL_FILE = os.path.join(DATA_DIR, "ascl.json")

def info(msg):
    """Print a line in blue (assumes we have a color terminal!)"""
    print("\033[1m\033[34m", "INFO:", msg, "\033[0m")


def urlretrieve(url, fname):
    info("Fetching " + url)
    r = requests.get(url)
    with open(os.path.join(fname), "w") as f:
        f.write(r.text)


def read_json(fname):
    with open(fname, "r") as f:
        return json.load(f)


def write_json(d, fname):
    with open(fname, "w") as f:
        json.dump(d, f)


def parse_pypi_html(html_doc, terms=None, strip_version=False):
    """Parse HTML page with package listing from PyPI.

    Parameters
    ----------
    html_doc : str
        HTML document.

    terms : list of str, optional
        If given, only include a package in results if its description includes
        one or more of these terms.

    strip_version : bool, optional
        If True, expect the package name to include a version number and
        strip it off.

    Returns
    -------
    packages : dict
        Dictionary where keys are package names and values are descriptions.
    """

    soup = BeautifulSoup(html_doc)
    result = {}

    # main table on page has class 'list'. Get table data elements from it.
    for row in soup.select("table[class~=list] tr"):
        cells = row.select("td")

        # Header row has no <td>'s and last row has one <td>. Skip these.
        if len(cells) != 2:
            continue

        # first column has an <a href...> element containing the package name.
        name = cells[0].a.string
        description = cells[1].string
        if strip_version:
            name = name.split('\xa0')[0]

        # crop duplicates
        if name in result:
            continue

        # search terms
        if terms is None:
            result[name] = description
        elif description is not None:
            for term in terms:
                if term in description.lower():
                    result[name] = description
                    break

    return result


def fetch_pypi():
    if not os.path.exists(PYPI_DATA_DIR):
        os.makedirs(PYPI_DATA_DIR)

    # Get names and descriptions of all "astronomy" packages.
    fname = os.path.join(PYPI_DATA_DIR, "packages.json")
    if not os.path.exists(fname):
        info("Fetching " + PYPI_CLASSIFIER_URL)
        r = requests.get(PYPI_CLASSIFIER_URL)
        info("Parsing " + PYPI_CLASSIFIER_URL)
        pkgs = parse_pypi_html(r.text)

        info("Fetching " + PYPI_MAIN_URL)
        r = requests.get(PYPI_MAIN_URL)
        info("Parsing " + PYPI_MAIN_URL)
        pkgs2 = parse_pypi_html(r.text, terms=["astro", "cosmo"],
                                strip_version=True)
        pkgs.update(pkgs2)

        write_json(pkgs, fname)
    else:
        pkgs = read_json(fname)

    # get and save data for each package
    for name in pkgs:
        url = PYPI_PACKAGE_URL.format(name)
        fname = os.path.join(PYPI_DATA_DIR, name + ".json")
        if not os.path.exists(fname):
            urlretrieve(url, fname)


def load_packages():
    pkgs = {}

    # PyPI
    fnames = os.listdir(PYPI_DATA_DIR)
    fnames.remove("packages.json")
    for fname in fnames:
        key = fname[:-5].lower()
        pkgs[key] = {'pypi': read_json(os.path.join(PYPI_DATA_DIR, fname))}

    # ASCL
    ascl = read_json(ASCL_FILE)
    for pkg in ascl.values():
        key = pkg["title"].split(":")[0].lower()
        if key not in pkgs:
            pkgs[key] = {}
        pkgs[key]['ascl'] = pkg

    return pkgs


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Fetch the data.")
    parser.add_argument("action", help="What to do?")
    args = parser.parse_args()

    if args.action == "fetch-pypi":
        fetch_pypi()
    elif args.action == "fetch-ascl":
        urlretrieve(ASCL_URL, ASCL_FILE)
    elif args.action == "analyze":
        pkgs = load_packages()
        pprint(pkgs["astropy"]["ascl"])
        pprint(pkgs["astropy"]["pypi"]["info"])
